{
    "filename": "FairretViolation",
    "metadata":
    {
        "name": "Fairret - Violation",
        "authors": "Maarten Buyl, MaryBeth Defrance, and Tijl De Bie",
        "version": "0.1.3",
        "license": "MIT",
        "source_paper": "\\textit{fairret: a Framework for Differentiable Fairness Regularization Terms} \\cite{buyl2024fairret}"
    },
    "description":
    {
        "method_type": ["Regularization"],
        "task": ["Binary Classification", "Soft Labels"],
        "compatible_data": ["Tabular Datasets", "Image Datasets"],
        "method_description":"A FAIRRET quantifies a model’s unfairness as a single value that is minimized like any other objective through automatic differentiation."
    },
    "pipeline":
    {
        "pipeline_location": "In-Processing",
        "compatible_model": ["Neural Networks"],
        "model_description": "The method is designed to be implemented in neural networks, however any method that uses gradients could be used."
    },
    "fairness":
    {
        "composition_features": ["Parallel Attributes", "Numerical Attribute"],
        "fairness_guarantee": "Tunable Fairness Strength",
        "fairness_type_defs": [
            {
            "fairness_type": "Group Fairness",
            "fairness_definitions": ["Demographic Parity", "Equal Opportunity", "Predictive Equality", "Predictive Parity", "False Omission Rate Parity", "Overall Accuracy Equality", "Treatment Equality", "F1-score Equality"]
            }
        ],
        "fairness_description": "A violation FAIRRET uses the proportion to which the fairness measure differs from the c-fixed measure as an added regularization term. This c-fixed measure is the average value for the measure within a batch, as this will be an integer it allows for the linear-fractional fairness measures to be transformed into linear equations. The method can account for numerical attributes, however linear behavior is expected."
    },
    "implementation":
    {
        "packages": [{"programming_language": "Python",
                      "related_packages": ["PyTorch"] }],
        "description": "The package is implemented to work with PyTorch. No experiments were conducted to confirm the performance on image datasets."
    },
    "use_cases": 
    {
        "cases": ["Bank \\cite{Moro_Cortez_Rita_2014}", "CreditCard \\cite{Yeh_Lien_2009}", "LawSchool (SEAPHE project)", "ACS Datasets \\cite{ding2021retiring}"],
        "description": ""
    },
    "bibliography": ["@inproceedings{buyl2024fairret, title={fairret: a Framework for Differentiable Fairness Regularization Terms}, author={Buyl, Maarten and Defrance, Marybeth and De Bie, Tijl}, booktitle={International Conference on Learning Representations}, year={2024}}",
                     "@article{Moro_Cortez_Rita_2014, title={A data-driven approach to predict the success of bank telemarketing}, volume={62}, ISSN={0167-9236}, DOI={10.1016/j.dss.2014.03.001},  journal={Decision Support Systems}, author={Moro, Sérgio and Cortez, Paulo and Rita, Paulo}, year={2014}, month=jun, pages={22–31} }",
                     "@article{Yeh_Lien_2009, title={The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients}, volume={36}, ISSN={0957-4174}, DOI={10.1016/j.eswa.2007.12.020}, number={2, Part 1}, journal={Expert Systems with Applications}, author={Yeh, I-Cheng and Lien, Che-hui}, year={2009}, month=mar, pages={2473–2480} }",
                     "@article{ding2021retiring, title={Retiring Adult: New Datasets for Fair Machine Learning}, author={Ding, Frances and Hardt, Moritz and Miller, John and Schmidt, Ludwig},journal={Advances in Neural Information Processing Systems},volume={34},year={2021}}"]
}